{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import Chat completion template and set-up variables\n",
    "%pip install openai==0.28.1 &> /dev/null\n",
    "import openai\n",
    "import urllib.parse\n",
    "\n",
    "openai.api_key = \"EMPTY\" # Key is ignored and does not matter\n",
    "openai.api_base = \"http://zanino.millennium.berkeley.edu:8000/v1\"\n",
    "# Alternate mirrors\n",
    "# openai.api_base = \"http://34.132.127.197:8000/v1\"\n",
    "\n",
    "# Report issues\n",
    "def raise_issue(e, model, prompt):\n",
    "    issue_title = urllib.parse.quote(\"[bug] Hosted Gorilla: <Issue>\")\n",
    "    issue_body = urllib.parse.quote(f\"Exception: {e}\\nFailed model: {model}, for prompt: {prompt}\")\n",
    "    issue_url = f\"https://github.com/ShishirPatil/gorilla/issues/new?assignees=&labels=hosted-gorilla&projects=&template=hosted-gorilla-.md&title={issue_title}&body={issue_body}\"\n",
    "    print(f\"An exception has occurred: {e} \\nPlease raise an issue here: {issue_url}\")\n",
    "\n",
    "# Query Gorilla server\n",
    "def get_gorilla_response(prompt=\"I would like to translate from English to French.\", model=\"gorilla-7b-hf-v1\"):\n",
    "  try:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=model,\n",
    "      messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "  except Exception as e:\n",
    "    raise_issue(e, model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<domain>>>: Natural Language Processing Text Generation\n",
      "<<<api_call>>>: generator = pipeline('text-generation', model='gpt2-large')\n",
      "<<<api_provider>>>: Transformers\n",
      "<<<explanation>>>: 1. Import the pipeline function from the transformers library provided by Hugging Face.\n",
      "2. Create a text-generation pipeline using the 'gpt2-large' model, which is a pre-trained generator model based on the Transformers architecture.\n",
      "3. Call the pipeline with a given description to generate 10 API calls that match the given input.\n",
      "<<<code>>>:\n",
      "from transformers import pipeline, set_seed\n",
      "\n",
      "def load_model():\n",
      "    generator = pipeline('text-generation', model='gpt2-large')\n",
      "    return generator\n",
      "\n",
      "def process_data(description, generator):\n",
      "    set_seed(42)\n",
      "    response = generator(description, max_length=100, num_return_sequences=10)\n",
      "    return response\n",
      "\n",
      "# Load the model\n",
      "generator = load_model()\n",
      "\n",
      "# Generate 10 API calls with description\n",
      "description = \"Generate 10 API calls with description: \"\n",
      "response = process_data(description, generator)\n",
      "\n",
      "# Print the generated API calls\n",
      "for i, call in enumerate(response):\n",
      "    print(f\"API Call {i+1}: {call['generated_text']}\")\n"
     ]
    }
   ],
   "source": [
    "# Gorilla `gorilla-mpt-7b-hf-v1` with code snippets\n",
    "# Translation\n",
    "prompt = \"Generate 10 different API calls with description\"\n",
    "print(get_gorilla_response(prompt, model=\"gorilla-7b-hf-v1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the text you want to translate: \\\"Hello, world!\\\"<input_text>>>: \\\"Hello, world!\\\"<api_call>>>: pipeline('translation_en_to_zh', model='Helsinki-NLP/opus-mt-en-zh')\\n<<<api_provider>>>: Hugging Face Transformers<explanation>>>: 1. We import the pipeline function from the transformers library provided by Hugging Face.<2. The pipeline function is used to create a translation model for English to Chinese using the 'Helsinki-NLP/opus-mt-en-zh' model. This model has been trained on a large corpus of text to perform translations between English and Chinese.<3. We input the text we want to translate into the model's input, and it returns the translated text in Chinese as output.<code>>>: from transformers import pipeline\\ntranslation_model = pipeline('translation_en_to_zh', model='Helsinki-NLP/opus-mt-en-zh')\\ntranslated_text = translation_model(\\\"Hello, world!\\\")\\n\" \n"
     ]
    }
   ],
   "source": [
    "# Gorilla with `gorilla-mpt-7b-hf-v0`\n",
    "prompt = \"I would like to translate from English to Chinese.\"\n",
    "print(get_gorilla_response(prompt, model=\"gorilla-mpt-7b-hf-v0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain': 'Machine Translation', 'api_call': 'model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)', 'api_provider': 'PyTorch', 'explanation': 'Load the pretrained ResNeSt-200 model from PyTorch Hub for English-to-Chinese machine translation, which can provide fast and accurate translation for your source text.', 'code': 'import torch\\ntarget_lang = 'zh-hant'\\nmodel = torch.hub.load('zhanghang1989/ResNeSt', 'resnest200', pretrained=True)'}\"\n"
     ]
    }
   ],
   "source": [
    "# Translation ‚úç with Torch Hub\n",
    "prompt = \"I would like to translate from English to Chinese.\"\n",
    "print(get_gorilla_response(prompt, model=\"gorilla-7b-th-v0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
