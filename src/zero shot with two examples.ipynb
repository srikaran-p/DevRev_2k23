{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/65/f4/dea10c11f0c2ebca298ba57f546940f8944e49c624239183c924ae0e1f81/langchain-0.0.339-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.339-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/30/1d/27c3571504fb6fb1e9f7c906d93590ead22f5f34910489e155ee28512eeb/openai-1.3.5-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.3.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting cohere\n",
      "  Obtaining dependency information for cohere from https://files.pythonhosted.org/packages/6c/b9/67b691fc5a8fa208435f85b38671d36238ab81eb1e7190c7c1e3b34892c7/cohere-4.36-py3-none-any.whl.metadata\n",
      "  Downloading cohere-4.36-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/94/2f/0cc8fb3436d421d8fa2da370aca0283201f1b99e88a0f6e742bd8eef397d/tiktoken-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (3.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/8d/e2/528c52001a743a7faa28e6d3095d9f01b472d3efee62d62101403bf1a70a/dataclasses_json-0.6.2-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.63 from https://files.pythonhosted.org/packages/84/9e/208314830d8c523dae4dec41ab5aeeb2d42dc1667bbc3ff8b875244b3012/langsmith-0.0.66-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.66-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/82/61/a5fca4a1e88e40969bbd0cf0d981f3aa76d5057db160b94f49603fc18740/httpx-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm>4 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (4.7.1)\n",
      "Collecting backoff<3.0,>=2.0 (from cohere)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting fastavro==1.8.2 (from cohere)\n",
      "  Obtaining dependency information for fastavro==1.8.2 from https://files.pythonhosted.org/packages/5b/74/da6fd6b4a818b9ffa4912988c47e432716ab03a4b5015524aabf5a9aa519/fastavro-1.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading fastavro-1.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from cohere) (6.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /raid/test1/anaconda3/lib/python3.11/site-packages (from cohere) (1.26.16)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /raid/test1/anaconda3/lib/python3.11/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /raid/test1/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /raid/test1/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /raid/test1/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /raid/test1/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /raid/test1/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /raid/test1/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /raid/test1/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /raid/test1/anaconda3/lib/python3.11/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.11.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /raid/test1/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /raid/test1/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.0.339-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-4.36-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
      "Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.66-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-inspect, marshmallow, jsonpatch, h11, fastavro, distro, backoff, tiktoken, langsmith, httpcore, dataclasses-json, langchain, httpx, cohere, openai\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed backoff-2.2.1 cohere-4.36 dataclasses-json-0.6.2 distro-1.8.0 fastavro-1.8.2 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 jsonpatch-1.33 langchain-0.0.339 langsmith-0.0.66 marshmallow-3.20.1 openai-1.3.5 tiktoken-0.5.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai cohere tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "example_file = open(\"../json/example.json\",\"r\")\n",
    "test_file = open(\"../json/test.json\",\"r\")\n",
    "format = open(\"../json/format.json\",\"r\").read()\n",
    "tools = open(\"../json/tools.json\",\"r\").read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get examples\n",
    "test_examples = json.loads(test_file.read())\n",
    "examples = json.loads(example_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template= \"\"\"\n",
    "{tools_template}\n",
    "\n",
    "{format_template}\n",
    "\n",
    "{example_template}\n",
    "\n",
    "{start_template}\n",
    "\"\"\"\n",
    "\n",
    "tools_template = \"\"\"\n",
    "Use the following tools and answer the given question using given answer format, \n",
    "{tools}\n",
    "\"\"\"\n",
    "answer_format_template = \"\"\"\n",
    "Generated answer for any given question should have following format\n",
    "{format}\n",
    "\"\"\"\n",
    "\n",
    "example_template = \"\"\"\n",
    "Following are the example of question-answer pairs for the abovementioned tools\n",
    "Example 1\n",
    "{example1}\n",
    "\n",
    "Example 2\n",
    "{example2}\n",
    "\"\"\"\n",
    "\n",
    "start_template = \"\"\"\n",
    "To reference the value of the ith tool in the chain, use $$PREV[i] as argument value. i = 0, 1, .. j-1; j = current tool’s index in the array\n",
    "If the query could not be answered with the given set of tools, output an empty list instead.\n",
    "\n",
    "Empty list should look like []. Whenever you want to access information about current user to pass it further, you need to make a call to whoami api tool.\n",
    "\n",
    "Answer the following question based on instructions provided above.\n",
    "question: {question}\n",
    "answer:{{\n",
    "\"question\":\n",
    "\"answer\":\n",
    "}}\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example1', 'format', 'example2', 'tools', 'question']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "full_prompt = PromptTemplate.from_template(prompt_template)\n",
    "tools_prompt = PromptTemplate.from_template(tools_template)\n",
    "answer_format_prompt = PromptTemplate.from_template(answer_format_template)\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "start_prompt = PromptTemplate.from_template(start_template)\n",
    "\n",
    "input_prompt = [\n",
    "    (\"tools_template\",tools_prompt),\n",
    "    (\"format_template\",answer_format_prompt),\n",
    "    (\"example_template\",example_prompt),\n",
    "    (\"start_template\",start_prompt)\n",
    "]\n",
    "prompt = PipelinePromptTemplate(final_prompt=full_prompt,pipeline_prompts=input_prompt)\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../prompt/zero_shot_with_two_example.txt\",\"w\")\n",
    "file.write(prompt.format(question=\"\",tools=tools,format=format,example1=examples[0],example2=examples[1]))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /raid/test1/anaconda3/lib/python3.11/site-packages (1.3.5)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: tqdm>4 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /raid/test1/anaconda3/lib/python3.11/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /raid/test1/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /raid/test1/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /raid/test1/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /raid/test1/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /raid/test1/anaconda3/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "config = open(\"config.txt\",\"r\").read()\n",
    "OPENAI_API_KEY=config\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../models/llama-2-7b-32k-instruct.Q8_0.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:            blk.0.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:              blk.0.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:            blk.1.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:              blk.1.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:            blk.2.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:              blk.2.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:            blk.3.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:              blk.3.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:            blk.4.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:              blk.4.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:            blk.5.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:              blk.5.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:            blk.6.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:              blk.6.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:            blk.7.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:              blk.7.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:            blk.8.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:              blk.8.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:            blk.9.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:              blk.9.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:           blk.10.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:             blk.10.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:           blk.11.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:             blk.11.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:           blk.12.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:             blk.12.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:           blk.13.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:             blk.13.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:           blk.14.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:             blk.14.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:           blk.15.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:             blk.15.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:           blk.16.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:             blk.16.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:           blk.17.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:             blk.17.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:           blk.18.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:             blk.18.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:           blk.19.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:             blk.19.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:           blk.20.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:             blk.20.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:           blk.21.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:             blk.21.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:           blk.22.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:             blk.22.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:           blk.23.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:             blk.23.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_down.weight q8_0     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.ffn_up.weight q8_0     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q8_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = togethercomputer_llama-2-7b-32k-instruct\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                    llama.rope.scale_linear f32              = 8.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 0.125\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q8_0\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 6.67 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name   = togethercomputer_llama-2-7b-32k-instruct\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: mem required  = 6828.75 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  = 2048.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 740/2\n",
      "llama_build_graph: ****************************************************************\n",
      "llama_build_graph: not all non-view tensors have been processed with a callback\n",
      "llama_build_graph: this can indicate an inefficiency in the graph implementation\n",
      "llama_build_graph: build with LLAMA_OFFLOAD_DEBUG for more info\n",
      "llama_build_graph: ref: https://github.com/ggerganov/llama.cpp/pull/3837\n",
      "llama_build_graph: ****************************************************************\n",
      "llama_new_context_with_model: compute buffer total size = 7.56 MiB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "llm = LlamaCpp(model_path='../models/llama-2-7b-32k-instruct.Q8_0.gguf',n_ctx=4096)\n",
    "# chain = LLMChain(llm = ChatOpenAI(model='gpt-4'), prompt=prompt)\n",
    "chain = LLMChain(llm = llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     227.55 ms\n",
      "llama_print_timings:      sample time =      85.17 ms /   256 runs   (    0.33 ms per token,  3005.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   73315.60 ms /  2223 tokens (   32.98 ms per token,    30.32 tokens per second)\n",
      "llama_print_timings:        eval time =   38622.20 ms /   255 runs   (  151.46 ms per token,     6.60 tokens per second)\n",
      "llama_print_timings:       total time =  113283.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     227.55 ms\n",
      "llama_print_timings:      sample time =      85.40 ms /   256 runs   (    0.33 ms per token,  2997.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1073.90 ms /    29 tokens (   37.03 ms per token,    27.00 tokens per second)\n",
      "llama_print_timings:        eval time =   37977.28 ms /   255 runs   (  148.93 ms per token,     6.71 tokens per second)\n",
      "llama_print_timings:       total time =   39835.63 ms\n"
     ]
    }
   ],
   "source": [
    "response = []\n",
    "for test in test_examples:\n",
    "\n",
    "    print(test['question_id'])\n",
    "    # input = prompt.format(question=test['question'],tools=tools,format=format,examples=examples)\n",
    "    output = chain.invoke({'question':test['question'],'tools':tools,'format':format,'example1':examples[0],'example2':examples[1]})\n",
    "\n",
    "    answer = output['text']\n",
    "    if (answer.find('{') < 0):\n",
    "        answer = []\n",
    "    else:\n",
    "        try:\n",
    "            answer = json.loads(output['text'])\n",
    "        except:\n",
    "            answer = json.loads(answer[answer.find(\"{\"):])\n",
    "    if (answer == []):\n",
    "        answer = {'question':test['question'],'answer':[]}\n",
    "    answer['question_id'] = test['question_id']\n",
    "    response.append(answer)\n",
    "    \n",
    "    if (test['question_id'] == '3'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'List all high severity tickets coming in from slack from customer Cust123 and generate a summary of them. ',\n",
       " 'tools': '[\\n    {\\n        \"tool_name\":\"works_list\",\\n        \"tool_description\":\"Returns a list of work items matching the request\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"applies_to_part\",\\n                \"description\":\"Filters for work belonging to any of the provided parts\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"FEAT-123\",\\n                \"ENH-123\",\\n                \"PROD-123\",\\n                \"CAPL-123\"]\\n            },\\n            {\\n                \"name\":\"created_by\",\\n                \"description\":\"Filters for work created by any of these users\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"DEVU-123\"]\\n            },\\n            {\\n                \"name\":\"issue.priority\",\\n                \"description\":\"Filters for issues with any of the provided priorities. Allowed values: p0, p1, p2, p3\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"issue.rev_orgs\",\\n                \"description\":\"Filters for issues with any of the provided Rev organizations\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"REV-123\"]\\n            },\\n            {\\n                \"name\":\"imit\",\\n                \"description\":\"The maximum number of works to return. The default is \\'50\\'\",\\n                \"type\":\"Integer (int32)\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"owned_by\",\\n                \"description\":\"Filters for work owned by any of these users\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"DEVU-123\"]\\n            },\\n            {\\n                \"name\":\"stage.name\",\\n                \"description\":\"Filters for records in the provided stage(s) by name\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"ticket.needs_response\",\\n                \"description\":\"Filters for tickets that need a response\",\\n                \"type\":\"boolean\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"ticket.rev_org\",\\n                \"description\":\"Filters for tickets associated with any of the provided Rev organizations\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"REV-123\"]\\n            },\\n            {\\n                \"name\":\"ticket.severity\",\\n                \"description\":\"Filters for tickets with any of the provided severities. Allowed values: blocker, high, low, medium\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"ticket.source_channel\",\\n                \"description\":\"Filters for tickets with any of the provided source channels\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"type\",\\n                \"description\":\"Filters for work of the provided types. Allowed values: issue, ticket, task\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"summarize_objects\",\\n        \"tool_description\":\"Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"objects\",\\n                \"description\":\"List of objects to summarize\",\\n                \"type\":\"array of objects\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"prioritize_objects\",\\n        \"tool_description\":\"Returns a list of objects sorted by priority. The logic of what constitutes priority for a given object is an internal implementation detail\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"objects\",\\n                \"description\":\"A list of objects to be prioritized\",\\n                \"type\":\"array of objects\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"add_work_items_to_sprint\",\\n        \"tool_description\":\"Adds the given work items to the sprint\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"work_ids\",\\n                \"description\":\"A list of work item IDs to be added to the sprint\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"sprint_id\",\\n                \"description\":\"The ID of the sprint to which the work items should be added\",\\n                \"type\":\"str\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"get_sprint_id\",\\n        \"tool_description\":\"Returns the ID of the current sprint\",\\n        \"arguments\":[\\n            \\n        ]\\n    },\\n    {\\n        \"tool_name\":\"get_similar_work_items\",\\n        \"tool_description\":\"Returns a list of work items that are similar to the given work item\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"work_id\",\\n                \"description\":\"The ID of the work item for which you want to find similar items\",\\n                \"type\":\"string\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"search_object_by_name\",\\n        \"tool_description\":\"Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"query\",\\n                \"description\":\"The search string, could be for example customer\\'s name, part name, user name.\",\\n                \"type\":\"string\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"create_actionable_tasks_from_text\",\\n        \"tool_description\":\"Given a text, extracts actionable insights, and creates tasks for them, which are kind of a work item.\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"text\",\\n                \"description\":\"The text from which the actionable insights need to be created.\",\\n                \"type\":\"string\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"who_am_i\",\\n        \"tool_description\":\"Returns the ID of the current user\",\\n        \"arguments\":[\\n            \\n        ]\\n    }\\n]',\n",
       " 'format': '{\\n    \"type\": \"array\",\\n    \"items\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"tool_name\": { \"type\": \"string\" },\\n            \"arguments\": {\\n                \"type\": \"array\",\\n                \"items\": {\\n                    \"type\": \"object\",\\n                    \"properties\": {\\n                        \"argument_name\": { \"type\": \"string\" },\\n                        \"argument_value\": { \"type\": \"string\" }\\n                    },\\n                    \"required\": [\"argument_name\", \"argument_value\"]\\n                }\\n            }\\n        },\\n        \"required\": [\"tool_name\", \"arguments\"]\\n    }\\n}',\n",
       " 'example1': {'question_id': '1',\n",
       "  'question': 'Summarize issues similar to don:core:dvrv-us-1:devo/0:issue/1',\n",
       "  'answer': [{'tool_name': 'get_similar_work_items',\n",
       "    'arguments': [{'argument_name': 'work_id',\n",
       "      'argument_value': 'don:core:dvrv-us-1:devo/0:issue/1'}]},\n",
       "   {'tool_name': 'summarize_objects',\n",
       "    'arguments': [{'argument_name': 'objects',\n",
       "      'argument_value': '$$PREV[0]'}]}]},\n",
       " 'example2': {'question_id': '4',\n",
       "  'question': 'Summarize high severity tickets from the customer UltimateCustomer',\n",
       "  'answer': [{'tool_name': 'search_object_by_name',\n",
       "    'arguments': [{'argument_name': 'query',\n",
       "      'argument_value': 'UltimateCustomer'}]},\n",
       "   {'tool_name': 'works_list',\n",
       "    'arguments': [{'argument_name': 'ticket.rev_org',\n",
       "      'argument_value': ['$$PREV[0]']},\n",
       "     {'argument_name': 'ticket.severity', 'argument_value': ['high']},\n",
       "     {'argument_name': 'type', 'argument_value': ['ticket']}]},\n",
       "   {'tool_name': 'summarize_objects',\n",
       "    'arguments': [{'argument_name': 'objects',\n",
       "      'argument_value': '$$PREV[1]'}]}]},\n",
       " 'text': '\\nExpected answer: [{\"type\": \"array\", \"items\": [{\"tool_name\": \"search_object_by_name\", \"arguments\": [{\"argument_name\": \"query\", \"argument_value\": \"Cust123\"}]}, {\"tool_name\": \"works_list\", \"arguments\": [{\"argument_name\": \"ticket.rev_org\", \"argument_value\": [\"$$PREV[0]\"]}, {\"argument_name\": \"ticket.severity\", \"argument_value\": [\"high\"]}, {\"argument_name\": \"type\", \"argument_value\": [\"ticket\"]}]}, {\"tool_name\": \"summarize_objects\", \"arguments\": [{\"argument_name\": \"objects\", \"argument_value\": \\'$$PREV[1]\\'}]}]}], \"required\": [\"tool_name\", \"arguments\"]}]'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the meaning of life?',\n",
       " 'tools': '[\\n    {\\n        \"tool_name\":\"works_list\",\\n        \"tool_description\":\"Returns a list of work items matching the request\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"applies_to_part\",\\n                \"description\":\"Filters for work belonging to any of the provided parts\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"FEAT-123\",\\n                \"ENH-123\",\\n                \"PROD-123\",\\n                \"CAPL-123\"]\\n            },\\n            {\\n                \"name\":\"created_by\",\\n                \"description\":\"Filters for work created by any of these users\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"DEVU-123\"]\\n            },\\n            {\\n                \"name\":\"issue.priority\",\\n                \"description\":\"Filters for issues with any of the provided priorities. Allowed values: p0, p1, p2, p3\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"issue.rev_orgs\",\\n                \"description\":\"Filters for issues with any of the provided Rev organizations\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"REV-123\"]\\n            },\\n            {\\n                \"name\":\"imit\",\\n                \"description\":\"The maximum number of works to return. The default is \\'50\\'\",\\n                \"type\":\"Integer (int32)\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"owned_by\",\\n                \"description\":\"Filters for work owned by any of these users\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"DEVU-123\"]\\n            },\\n            {\\n                \"name\":\"stage.name\",\\n                \"description\":\"Filters for records in the provided stage(s) by name\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"ticket.needs_response\",\\n                \"description\":\"Filters for tickets that need a response\",\\n                \"type\":\"boolean\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"ticket.rev_org\",\\n                \"description\":\"Filters for tickets associated with any of the provided Rev organizations\",\\n                \"type\":\"array of strings\",\\n                \"example\":[\"REV-123\"]\\n            },\\n            {\\n                \"name\":\"ticket.severity\",\\n                \"description\":\"Filters for tickets with any of the provided severities. Allowed values: blocker, high, low, medium\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"ticket.source_channel\",\\n                \"description\":\"Filters for tickets with any of the provided source channels\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"type\",\\n                \"description\":\"Filters for work of the provided types. Allowed values: issue, ticket, task\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"summarize_objects\",\\n        \"tool_description\":\"Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"objects\",\\n                \"description\":\"List of objects to summarize\",\\n                \"type\":\"array of objects\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"prioritize_objects\",\\n        \"tool_description\":\"Returns a list of objects sorted by priority. The logic of what constitutes priority for a given object is an internal implementation detail\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"objects\",\\n                \"description\":\"A list of objects to be prioritized\",\\n                \"type\":\"array of objects\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"add_work_items_to_sprint\",\\n        \"tool_description\":\"Adds the given work items to the sprint\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"work_ids\",\\n                \"description\":\"A list of work item IDs to be added to the sprint\",\\n                \"type\":\"array of strings\",\\n                \"example\":\"\"\\n            },\\n            {\\n                \"name\":\"sprint_id\",\\n                \"description\":\"The ID of the sprint to which the work items should be added\",\\n                \"type\":\"str\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"get_sprint_id\",\\n        \"tool_description\":\"Returns the ID of the current sprint\",\\n        \"arguments\":[\\n            \\n        ]\\n    },\\n    {\\n        \"tool_name\":\"get_similar_work_items\",\\n        \"tool_description\":\"Returns a list of work items that are similar to the given work item\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"work_id\",\\n                \"description\":\"The ID of the work item for which you want to find similar items\",\\n                \"type\":\"string\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"search_object_by_name\",\\n        \"tool_description\":\"Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"query\",\\n                \"description\":\"The search string, could be for example customer\\'s name, part name, user name.\",\\n                \"type\":\"string\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"create_actionable_tasks_from_text\",\\n        \"tool_description\":\"Given a text, extracts actionable insights, and creates tasks for them, which are kind of a work item.\",\\n        \"arguments\":[\\n            {\\n                \"name\":\"text\",\\n                \"description\":\"The text from which the actionable insights need to be created.\",\\n                \"type\":\"string\",\\n                \"example\":\"\"\\n            }\\n        ]\\n    },\\n    {\\n        \"tool_name\":\"who_am_i\",\\n        \"tool_description\":\"Returns the ID of the current user\",\\n        \"arguments\":[\\n            \\n        ]\\n    }\\n]',\n",
       " 'format': '{\\n    \"type\": \"array\",\\n    \"items\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"tool_name\": { \"type\": \"string\" },\\n            \"arguments\": {\\n                \"type\": \"array\",\\n                \"items\": {\\n                    \"type\": \"object\",\\n                    \"properties\": {\\n                        \"argument_name\": { \"type\": \"string\" },\\n                        \"argument_value\": { \"type\": \"string\" }\\n                    },\\n                    \"required\": [\"argument_name\", \"argument_value\"]\\n                }\\n            }\\n        },\\n        \"required\": [\"tool_name\", \"arguments\"]\\n    }\\n}',\n",
       " 'example1': {'question_id': '1',\n",
       "  'question': 'Summarize issues similar to don:core:dvrv-us-1:devo/0:issue/1',\n",
       "  'answer': [{'tool_name': 'get_similar_work_items',\n",
       "    'arguments': [{'argument_name': 'work_id',\n",
       "      'argument_value': 'don:core:dvrv-us-1:devo/0:issue/1'}]},\n",
       "   {'tool_name': 'summarize_objects',\n",
       "    'arguments': [{'argument_name': 'objects',\n",
       "      'argument_value': '$$PREV[0]'}]}]},\n",
       " 'example2': {'question_id': '4',\n",
       "  'question': 'Summarize high severity tickets from the customer UltimateCustomer',\n",
       "  'answer': [{'tool_name': 'search_object_by_name',\n",
       "    'arguments': [{'argument_name': 'query',\n",
       "      'argument_value': 'UltimateCustomer'}]},\n",
       "   {'tool_name': 'works_list',\n",
       "    'arguments': [{'argument_name': 'ticket.rev_org',\n",
       "      'argument_value': ['$$PREV[0]']},\n",
       "     {'argument_name': 'ticket.severity', 'argument_value': ['high']},\n",
       "     {'argument_name': 'type', 'argument_value': ['ticket']}]},\n",
       "   {'tool_name': 'summarize_objects',\n",
       "    'arguments': [{'argument_name': 'objects',\n",
       "      'argument_value': '$$PREV[1]'}]}]},\n",
       " 'text': '\\nNote: You can use any tool to answer the question, but it must be in the format specified above.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"../output/zero shot with two examples/llama_7B_instruct_res.json\",\"w\")\n",
    "json.dump(response,outfile,indent=4)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
